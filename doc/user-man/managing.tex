This section provides a brief summary of what can be done once jobs
are submitted. The basic mechanisms for monitoring a job are
introduced, but the commands are discussed briefly.
You are encouraged to
look at the man pages of the commands referred to (located in
Chapter~\ref{command-reference} beginning on
page~\pageref{command-reference}) for more information. 

When jobs are submitted, Condor will attempt to find resources
to run the jobs. 
A list of all those with jobs submitted
may be obtained through \Condor{status}
\index{Condor commands!condor\_status}
with the 
\Arg{-submitters} option. 
An example of this would yield output similar to:
\begin{verbatim}
%  condor_status -submitters

Name                 Machine      Running IdleJobs HeldJobs

ballard@cs.wisc.edu  bluebird.c         0       11        0
nice-user.condor@cs. cardinal.c         6      504        0
wright@cs.wisc.edu   finch.cs.w         1        1        0
jbasney@cs.wisc.edu  perdita.cs         0        0        5

                           RunningJobs           IdleJobs           HeldJobs

 ballard@cs.wisc.edu                 0                 11                  0
 jbasney@cs.wisc.edu                 0                  0                  5
nice-user.condor@cs.                 6                504                  0
  wright@cs.wisc.edu                 1                  1                  0

               Total                 7                516                  5
\end{verbatim}

\subsection{Checking on the progress of jobs}
At any time, you can check on the status of your jobs with the \Condor{q}
command.
\index{Condor commands!condor\_q}
This command displays the status of all queued jobs.
An example of the output from \Condor{q} is
\begin{verbatim}
%  condor_q

-- Submitter: froth.cs.wisc.edu : <128.105.73.44:33847> : froth.cs.wisc.edu
 ID      OWNER            SUBMITTED    CPU_USAGE ST PRI SIZE CMD               
 125.0   jbasney         4/10 15:35   0+00:00:00 I  -10 1.2  hello.remote      
 127.0   raman           4/11 15:35   0+00:00:00 R  0   1.4  hello             
 128.0   raman           4/11 15:35   0+00:02:33 I  0   1.4  hello             

3 jobs; 2 idle, 1 running, 0 held

\end{verbatim} 
This output contains many columns of information about the
queued jobs.
\index{status!of queued jobs}
The \verb@ST@ column (for status) shows the status of
current jobs in the queue. An \verb@R@ in the status column
means the the job is currently running.
An \verb@I@ stands for idle. The job is not running right
now, because it is waiting for a machine to become available. 
The status
\verb@H@ is the hold state. In the hold state,
the job will not be scheduled to
run until it is released (see condor\_hold and condor\_release man pages).
Older versions of Condor used a
\verb@U@ in the status column to stand for unexpanded.
In this state,
a job has never 
checkpointed and when it starts running, it will start running from the
beginning.
Newer versions of Condor do not use the \verb@U@ state.

The \verb@CPU_USAGE@ time reported for a job is the time that has been
committed to the job.  It is not updated for a job until
the job checkpoints. At that time, the job has made guaranteed forward 
progress.  Depending upon how the site administrator configured the pool,
several hours may pass between checkpoints, so do not worry if you do
not observe the \verb@CPU_USAGE@ entry changing by the hour.
Also note that this is actual CPU
time as reported by the operating system; it is not time as
measured by a wall clock.

Another useful method of tracking the progress of jobs is through the
user log.  If you have specified a \AdAttr{log} command in 
your submit file, the progress of the job may be followed by viewing the
log file.  Various events such as execution commencement, checkpoint, eviction 
and termination are logged in the file.
Also logged is the time at which the event occurred.

% Karen's note:  degraded performance where?
When your job begins to run, Condor starts up a \Condor{shadow} process
\index{condor\_shadow}
\index{remote system call!condor\_shadow}
on the submit machine.  The shadow process is the mechanism by which the
remotely executing jobs can access the environment from which it was
submitted, such as input and output files.  

It is normal for a machine which has submitted hundreds of jobs to have 
hundreds of shadows running on the machine.  Since the text segments of 
all these processes is the same, the load on the submit machine is usually 
not significant.  If, however, you notice degraded performance, you can limit 
the number of jobs that can run simultaneously through the 
\Macro{MAX\_JOBS\_RUNNING} configuration parameter.  Please talk to your 
system administrator for the necessary configuration change.

You can also find all the machines that are running your job through the
\Condor{status} command.
\index{Condor commands!condor\_status}
For example, to find all the machines that are
running jobs submitted by ``breach@cs.wisc.edu,'' type:
\begin{verbatim}
%  condor_status -constraint 'RemoteUser == "breach@cs.wisc.edu"'

Name       Arch     OpSys        State      Activity   LoadAv Mem  ActvtyTime

alfred.cs. INTEL    SOLARIS251   Claimed    Busy       0.980  64    0+07:10:02
biron.cs.w INTEL    SOLARIS251   Claimed    Busy       1.000  128   0+01:10:00
cambridge. INTEL    SOLARIS251   Claimed    Busy       0.988  64    0+00:15:00
falcons.cs INTEL    SOLARIS251   Claimed    Busy       0.996  32    0+02:05:03
happy.cs.w INTEL    SOLARIS251   Claimed    Busy       0.988  128   0+03:05:00
istat03.st INTEL    SOLARIS251   Claimed    Busy       0.883  64    0+06:45:01
istat04.st INTEL    SOLARIS251   Claimed    Busy       0.988  64    0+00:10:00
istat09.st INTEL    SOLARIS251   Claimed    Busy       0.301  64    0+03:45:00
...
\end{verbatim}
To find all the machines that are running any job at all, type:
\begin{verbatim}
%  condor_status -run

Name       Arch     OpSys        LoadAv RemoteUser           ClientMachine  

adriana.cs INTEL    SOLARIS251   0.980  hepcon@cs.wisc.edu   chevre.cs.wisc.
alfred.cs. INTEL    SOLARIS251   0.980  breach@cs.wisc.edu   neufchatel.cs.w
amul.cs.wi SUN4u    SOLARIS251   1.000  nice-user.condor@cs. chevre.cs.wisc.
anfrom.cs. SUN4x    SOLARIS251   1.023  ashoks@jules.ncsa.ui jules.ncsa.uiuc
anthrax.cs INTEL    SOLARIS251   0.285  hepcon@cs.wisc.edu   chevre.cs.wisc.
astro.cs.w INTEL    SOLARIS251   1.000  nice-user.condor@cs. chevre.cs.wisc.
aura.cs.wi SUN4u    SOLARIS251   0.996  nice-user.condor@cs. chevre.cs.wisc.
balder.cs. INTEL    SOLARIS251   1.000  nice-user.condor@cs. chevre.cs.wisc.
bamba.cs.w INTEL    SOLARIS251   1.574  dmarino@cs.wisc.edu  riola.cs.wisc.e
bardolph.c INTEL    SOLARIS251   1.000  nice-user.condor@cs. chevre.cs.wisc.
...
\end{verbatim}

\subsection{Removing a job from the queue}
A job can be removed from the queue at any time by using the \Condor{rm}
\index{Condor commands!condor\_rm}
command.  If the job that is being removed is currently running, the job
is killed without a checkpoint, and its queue entry is removed.  
The following example shows the queue of jobs before and after
a job is removed.
\begin{verbatim}
%  condor_q

-- Submitter: froth.cs.wisc.edu : <128.105.73.44:33847> : froth.cs.wisc.edu
 ID      OWNER            SUBMITTED    CPU_USAGE ST PRI SIZE CMD               
 125.0   jbasney         4/10 15:35   0+00:00:00 I  -10 1.2  hello.remote      
 132.0   raman           4/11 16:57   0+00:00:00 R  0   1.4  hello             

2 jobs; 1 idle, 1 running, 0 held

%  condor_rm 132.0
Job 132.0 removed.

%  condor_q

-- Submitter: froth.cs.wisc.edu : <128.105.73.44:33847> : froth.cs.wisc.edu
 ID      OWNER            SUBMITTED    CPU_USAGE ST PRI SIZE CMD               
 125.0   jbasney         4/10 15:35   0+00:00:00 I  -10 1.2  hello.remote      

1 jobs; 1 idle, 0 running, 0 held
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\label{sec:job-prio}Changing the priority of jobs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{job!priority}
\index{priority!of a job}
In addition to the priorities assigned to each user, Condor also provides
each user with the capability of assigning priorities to each submitted job.
These job priorities are local to each queue and range from -20 to +20, with
higher values meaning better priority.

The default priority of a job is 0, but can be changed using the \Condor{prio}
command.
\index{Condor commands!condor\_prio}
For example, to change the priority of a job to -15,
\begin{verbatim}
%  condor_q raman

-- Submitter: froth.cs.wisc.edu : <128.105.73.44:33847> : froth.cs.wisc.edu
 ID      OWNER            SUBMITTED    CPU_USAGE ST PRI SIZE CMD               
 126.0   raman           4/11 15:06   0+00:00:00 I  0   0.3  hello             

1 jobs; 1 idle, 0 running, 0 held

%  condor_prio -p -15 126.0

%  condor_q raman

-- Submitter: froth.cs.wisc.edu : <128.105.73.44:33847> : froth.cs.wisc.edu
 ID      OWNER            SUBMITTED    CPU_USAGE ST PRI SIZE CMD               
 126.0   raman           4/11 15:06   0+00:00:00 I  -15 0.3  hello             

1 jobs; 1 idle, 0 running, 0 held
\end{verbatim}

It is important to note that these \emph{job} priorities are completely 
different from the \emph{user} priorities assigned by Condor.  Job priorities
do not impact user priorities.  They are only a mechanism for the user to
identify the relative importance of jobs among all the jobs submitted by the
user to that specific queue.

\subsection{Why does the job not run?}
\index{job!analysis}
\index{job!not running}
Users sometimes find that their jobs do not run.  There are several reasons why
a specific job does not run.  These reasons include failed job or machine
constraints, bias due to preferences, insufficient priority, and the preemption
throttle that is implemented by the \Condor{negotiator} to prevent
thrashing.  Many of these reasons can be diagnosed by using the \Arg{-analyze}
option of \Condor{q}.
\index{Condor commands!condor\_q}
For example, the following job submitted by user
jbasney was found to have not run for several days.
\begin{verbatim}
% condor_q

-- Submitter: froth.cs.wisc.edu : <128.105.73.44:33847> : froth.cs.wisc.edu
 ID      OWNER            SUBMITTED    CPU_USAGE ST PRI SIZE CMD               
 125.0   jbasney         4/10 15:35   0+00:00:00 I  -10 1.2  hello.remote      

1 jobs; 1 idle, 0 running, 0 held
\end{verbatim}

Running \Condor{q}'s analyzer provided the following information:

\begin{verbatim}
%  condor_q 125.0 -analyze

-- Submitter: froth.cs.wisc.edu : <128.105.73.44:33847> : froth.cs.wisc.edu
---
125.000:  Run analysis summary.  Of 323 resource offers,
          323 do not satisfy the request's constraints
            0 resource offer constraints are not satisfied by this request
            0 are serving equal or higher priority customers
            0 are serving more preferred customers
            0 cannot preempt because preemption has been held
            0 are available to service your request

WARNING:  Be advised:
   No resources matched request's constraints
   Check the Requirements expression below:

Requirements = Arch == "INTEL" && OpSys == "IRIX6" && 
  Disk >= ExecutableSize && VirtualMemory >= ImageSize
\end{verbatim}

%%%%%%%%%%%%%%%%%%%
%condor_status -total lists the Arch/OS combinations in our pool:
%
%                     Machines Owner Claimed Unclaimed Matched Preempting
%
%           SGI/IRIX6       14     3       0        11       0          0
%          ALPHA/OSF1        8     6       1         1       0          0
%     SUN4u/SOLARIS26       84    38      46         0       0          0
%    SUN4u/SOLARIS251        8     0       1         7       0          0
%     SUN4x/SOLARIS26      104    47      56         1       0          0
%    SUN4x/SOLARIS251        1     0       1         0       0          0
%     INTEL/SOLARIS26      214    63     144         7       0          0
%       INTEL/WINNT40        6     0       0         6       0          0
%
%               Total      439   157     249        33       0          0
%
%So, one example of a platform that does not exist would be:
%
% requirements = Arch == "INTEL" && OpSys == "IRIX6"
%
%%%%%%%%%%%%%%%%%%%

For this job,
the \Attr{Requirements}
\index{ClassAd attribute!requirements}
expression specifies a platform that does not exist.
Therefore, the expression always evaluates to false.

While the analyzer can diagnose most common problems, there are some situations
that it cannot reliably detect due to the instantaneous and local nature of the
information it uses to detect the problem.  Thus, it may be that the analyzer
reports that resources are available to service the request, but the job still 
does not run.  In most of these situations, the delay is transient, and the
job will run during the next negotiation cycle.

If the problem persists and the analyzer is unable to detect the situation, it
may be that the job begins to run but immediately terminates due to some 
problem.  Viewing the job's error and log files
(specified in the submit command file) and Condor's \Macro{SHADOW\_LOG} file
may assist in tracking down the problem.  If the cause is still unclear, please
contact your system administrator.

\subsection{\label{sec:job-completion}Job Completion}
\index{job!completion}

When your Condor job completes(either through normal means or abnormal
termination by signal), Condor will remove it from the job queue (i.e.,
it will no longer appear in the output of \Condor{q}) and insert it into
the job history file.  You can examine the job history file with the
\Condor{history} command. If you specified a log file in your submit
description file, then the job exit status will be recorded there as well.

By default, Condor will send you an email message
when your job completes.  You can modify this behavior with the
\Condor{submit} ``notification'' command.
The message will include the exit status of your job (i.e., the
argument your job passed to the exit system call when it completed) or
notification that your job was killed by a signal.  It will also
include the following statistics (as appropriate) about your job:

\begin{description}

\item[Submitted at:] when the job was submitted with \Condor{submit}

\item[Completed at:] when the job completed

\item[Real Time:] elapsed time between when the job was submitted and
when it completed (days hours:minutes:seconds)

\item[Run Time:] total time the job was running (i.e., real time minus
queueing time)

\item[Committed Time:] total run time that contributed to job
completion (i.e., run time minus the run time that was lost because
the job was evicted without performing a checkpoint)

\item[Remote User Time:] total amount of committed time the job spent
executing in user mode

\item[Remote System Time:] total amount of committed time the job spent
executing in system mode 

\item[Total Remote Time:] total committed CPU time for the job

\item[Local User Time:] total amount of time this job's
\Condor{shadow} (remote system call server) spent executing in user
mode

\item[Local System Time:] total amount of time this job's
\Condor{shadow} spent executing in system mode

\item[Total Local Time:] total CPU usage for this job's \Condor{shadow}

\item[Leveraging Factor:] the ratio of total remote time to total
system time (a factor below 1.0 indicates that the job ran
inefficiently, spending more CPU time performing remote system calls
than actually executing on the remote machine)

\item[Virtual Image Size:] memory size of the job, computed when the
job checkpoints

\item[Checkpoints written:] number of successful checkpoints performed
by the job

\item[Checkpoint restarts:] number of times the job successfully
restarted from a checkpoint

\item[Network:] total network usage by the job for checkpointing and
remote system calls

\item[Buffer Configuration:] configuration of remote system call I/O
buffers

\item[Total I/O:] total file I/O detected by the remote system call
library

\item[I/O by File:] I/O statistics per file produced by the remote
system call library

\item[Remote System Calls:] listing of all remote system calls
performed (both Condor-specific and Unix system calls) with a count of
the number of times each was performed

\end{description}
