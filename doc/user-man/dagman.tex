%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\label{sec:DAGMan}DAGMan Applications}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\index{DAGMan|(}
\index{directed acyclic graph}
\index{Directed Acyclic Graph Manager (DAGMan)}
\index{condor\_submit\_dag}
\index{job!dependencies}

A directed acyclic graph (DAG) can be used to represent a set of programs
where the input, output, or execution of one or more programs
is dependent on one or more other programs.
The programs are nodes (vertices) in the graph,
and the edges (arcs) identify the dependencies.
Condor finds machines for the execution of programs, but it
does not schedule programs (jobs) based on dependencies.
The Directed Acyclic Graph Manager (DAGMan) is a meta-scheduler for Condor
jobs. 
DAGMan submits jobs to Condor in an order represented by
a DAG and processes the results.
An input file defined prior to submission describes the DAG, and
a Condor submit description file for each program in the DAG
is used by Condor.

Each node (program) in the DAG specifies a Condor submit description file.
As DAGMan submits jobs to Condor, it monitors the Condor log file(s) to 
to enforce the ordering required for the DAG.

The DAG itself is defined by the contents of a DAGMan input file.
DAGMan is responsible for scheduling, recovery, and reporting
for the set of programs submitted to Condor.

The following sections specify the use of DAGMan.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Input File describing the DAG}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{DAGMan!input file example}
The input file used by DAGMan specifies six items:
\begin{enumerate}
\item
A list of the programs in the DAG. This serves to name each program
and specify each program's Condor submit description file.
\item
Processing that takes place before submission of
any program in the DAG to Condor or after Condor has completed execution
of any program in the DAG (optional).
\item
Description of the dependencies in the DAG.
\item
Number of times to retry if a node within the DAG fails (optional).
\item
The definition of macros associated with a node (optional).
\item
A node exit value that will abort the entire DAG (optional).
\end{enumerate}

Comments may be placed in the input file that describes the DAG.
The pound character (\verb@#@) as the first character on a
line identifies the line as a comment.
Comments do not span lines.

An example input file for DAGMan is

\begin{verbatim}
	# Filename: diamond.dag
	#
	JOB  A  A.condor 
	JOB  B  B.condor 
	JOB  C  C.condor	
	JOB  D  D.condor
	Script PRE  A top_pre.csh
	Script PRE  B mid_pre.perl  $JOB
	Script POST B mid_post.perl $JOB $RETURN
	Script PRE  C mid_pre.perl  $JOB
	Script POST C mid_post.perl $JOB $RETURN
	Script PRE  D bot_pre.csh
	PARENT A CHILD B C
	PARENT B C CHILD D
	Retry  C 3
	VARS A state="Wisconsin"
	ABORT-DAG-ON C 10
\end{verbatim}

This input file describes the DAG shown in 
Figure~\ref{fig:dagman-diamond}.

\begin{figure}[hbt]
\centering
\includegraphics{user-man/dagman-diamond.eps}
\caption{\label{fig:dagman-diamond}Diamond DAG}
\end{figure}

DAGMan has the ability to manage different types of jobs.  Condor CPU
jobs are indicated with the \Arg{JOB} keyword.  Stork data placement
jobs are indicated with the \Arg{DATA} keyword.  All \Arg{JobName}s,
irrespective of type, must be unique.  Otherwise, the term \Term{Job}
or \Term{job} will indicate a generic job, of any type.

Each DAG file keyword is described below.

\subsubsection{\label{dagman:JOB}JOB}

\index{DAGMan!Job Entry (names node of DAG)}
The first section of the input file lists
all the programs that appear in the DAG.
Each program to be managed by Condor is described by a single line
called a \Arg{JOB} Entry.
The syntax used for each Condor \Arg{JOB} Entry is

\Arg{JOB} \Arg{JobName} \Arg{SubmitDescriptionFileName} \oArg{DONE}

A \Arg{JOB} Entry maps a \Arg{JobName} to a Condor submit description file.
The \Arg{JobName} uniquely identifies nodes within the
DAGMan input file and within output messages.

The keyword \Arg{JOB} and the \Arg{JobName} are not case sensitive.
A \Arg{JobName} of \Arg{joba} is equivalent to \Arg{JobA}.
The \Arg{SubmitDescriptionFileName} is case sensitive, since
the UNIX file system is case sensitive.
The \Arg{JobName} can be any string that contains no white space.

The optional \Arg{DONE} identifies a job as being already
completed.
This is useful in situations where the user wishes to verify results,
but does not need all programs within the dependency graph to be executed.
The \Arg{DONE} feature is also utilized when
an error occurs causing the DAG to not be completed.
DAGMan generates a Rescue DAG, a DAGMan input file that can be
used to restart and complete a DAG without re-executing
completed programs.

\subsubsection{\label{dagman:DATA}DATA}

The \Arg{DATA} keyword specifies a job to be managed by the Stork data
placement server.  
The syntax used for each Condor \Arg{DATA} Entry is

\Arg{DATA} \Arg{JobName} \Arg{SubmitDescriptionFileName} \oArg{DONE}

A \Arg{DATA} Entry maps a \Arg{JobName} to a Stork submit description file.
In all other respects, the \Arg{DATA} keyword is identical to the
\Arg{JOB} keyword, in section~\ref{dagman:JOB}.

Here's an example of a simple DAG that stages in data via Stork,
processes the data via Condor, and stages the processed data out via
Stork.  Depending upon the implementation, multiple data stage in jobs
may be run in parallel, and data stage out jobs may be run in
parallel:

\begin{verbatim}
	DATA    STAGE_IN1  stage_in1.stork
	DATA    STAGE_IN2  stage_in2.stork
	JOB     PROCESS    process.condor 
	DATA    STAGE_OUT1 stage_out1.stork
	DATA    STAGE_OUT2 stage_out2.stork
	PARENT  STAGE_IN1 STAGE_IN2  CHILD  PROCESS
	PARENT  PROCESS    CHILD  STAGE_OUT1 STAGE_OUT2
\end{verbatim}

\subsubsection{SCRIPT}

\index{DAGMan!PRE and POST scripts}
The second type of item in a DAGMan input file enumerates
processing that is done either before a program within
the DAG is submitted to Condor for execution
or after
a program within
the DAG completes its execution.
\index{DAGMan!PRE script}
Processing done before a program is submitted to Condor is
called a \Arg{PRE} script.
Processing done after a program completes
its execution under Condor is
\index{DAGMan!POST script}
called a \Arg{POST} script.
A node in the DAG is comprised of the program together with
\Arg{PRE} and/or \Arg{POST} scripts.
The dependencies in the DAG are enforced based on nodes.

Syntax for \Arg{PRE} and \Arg{POST} script lines within the input file:

\Arg{SCRIPT} \Arg{PRE} \Arg{JobName} \Arg{ExecutableName} \oArg{arguments}

\Arg{SCRIPT} \Arg{POST}  \Arg{JobName} \Arg{ExecutableName} \oArg{arguments}

The \Arg{SCRIPT} keyword identifies the type of line within
the DAG input file.
The \Arg{PRE} or \Arg{POST} keyword
specifies the relative timing of when the script is to be run.
The \Arg{JobName} specifies the node to which the script is attached.
The \Arg{ExecutableName}
specifies the script to be executed, and it
may be followed by any command line arguments to that script.
The \Arg{ExecutableName} and optional \Arg{arguments} have their
case preserved.

Scripts are optional for each job, and
any scripts are executed on the machine
to which the DAG is submitted (not necessarily
the machine on which the node's program is run).

The PRE and POST scripts are commonly used
when files must be placed into a staging area for the job to use,
and files are cleaned up or removed once the job is finished running.
An example using PRE/POST scripts involves staging files
that are stored on tape.
The PRE script reads compressed input files from the tape drive,
and it uncompresses them, placing the input files in the current directory.
The program within the DAG node is submitted to Condor,
and it reads these input files.
The program produces output files.
The POST script compresses the output files, writes them out to
the tape, and then deletes the staged input and output files.

DAGMan takes note of the exit value of the
scripts as well as the program.
If the PRE script fails (exit value != 0), then neither the program nor
the POST script runs, and the node is marked as failed.

If the PRE script succeeds, the program is submitted to Condor. 
If the program fails and there is no POST script,
the DAG node is marked as failed.
An exit value not equal to 0 indicates program failure.
It is therefore important that the program returns the exit
value 0 to indicate the program did not fail.

If the program fails and there is a POST script,
node failure is determined by the exit value of the POST script.
A failing value from the POST script marks the node as failed.
A succeeding value from the POST script (even with a failed
program) marks the node as successful.
Therefore, the POST script may need to consider the return
value from the program.

By default, the POST script is run regardless of the program's
return value.  To prevent POST scripts from running after failed jobs,
pass the \Arg{-NoPostFail} argument to \Condor{submit\_dag}.

A node not marked as failed at any point is successful.

Two variables are available to ease script writing.
The \Env{\$JOB} variable evaluates to \Arg{JobName}.
For POST scripts, the \Env{\$RETURN} variable evaluates to the return value of the program.
Jobs that are aborted, removed, preempted, etc. are passed a \Env{\$RETURN}
value of -6.
The variables may be
placed anywhere within the arguments.

As an example, suppose the \Arg{PRE} script expands a compressed file named
\File{\Arg{JobName}.gz}.
The \Arg{SCRIPT} entry for jobs A, B, and C are

\begin{verbatim}
	SCRIPT PRE  A  pre.csh $JOB .gz
	SCRIPT PRE  B  pre.csh $JOB .gz
	SCRIPT PRE  C  pre.csh $JOB .gz
\end{verbatim}

The script \File{pre.csh} may use these arguments

\begin{verbatim}
	#!/bin/csh
	gunzip $argv[1]$argv[2]
\end{verbatim}

% $ % this comment just has a dollar sign so that emacs will not think
%	  we're inside of a math section and will draw things more nicely

\subsubsection{\label{dagman:ParentChild}PARENT..CHILD}

The third type of item in the DAG input file describes the
dependencies within the DAG.
\index{DAGMan!describing dependencies}
Nodes are parents and/or children within the DAG.
A parent node must be completed successfully before
any child node may be started.
A child node is started once
all its parents have successfully completed.

The syntax of a dependency line within the DAG input file:

\Arg{PARENT} \Arg{ParentJobName\Dots} \Arg{CHILD} \Arg{ChildJobName\Dots}

The \Arg{PARENT} keyword is followed by one or more
\Arg{ParentJobName}s.
The \Arg{CHILD} keyword is followed by one or more
\Arg{ChildJobName}s.
Each child job depends on every parent job on the line.
A single line in the input file can specify the dependencies from one or more
parents to one or more children.
As an example, the line
\begin{verbatim}
PARENT p1 p2 CHILD c1 c2
\end{verbatim}
produces four dependencies:
\begin{enumerate}
\item{\verb@p1@ to \verb@c1@}
\item{\verb@p1@ to \verb@c2@}
\item{\verb@p2@ to \verb@c1@}
\item{\verb@p2@ to \verb@c2@}
\end{enumerate}

\subsubsection{RETRY}

\index{DAGMan!RETRY of failed nodes}
The fourth type of item in the DAG input file provides a
way (optional) to retry failed nodes.
The syntax for retry is

\Arg{RETRY} \Arg{JobName} \Arg{NumberOfRetries} \oArg{UNLESS-EXIT \textless{value}\textgreater}

where the \Arg{JobName} is the same as the name given in
a Job Entry line, and \Arg{NumberOfRetries} is an integer,
the number of times to retry the node after failure.
The default number of retries for any node is 0,
the same as not having a retry line in the file. 

In some cases, it is inappropriate to retry for the number of times
specified. For example, a PRE script may edit the job's submit file to
indicate what it should do, and if it runs out of possibilities after
a few retries, then there is no point in continuing to retry the
node. In this case, you can specify UNLESS-EXIT, and if any of the
parts of the node (PRE script, job, or POST script) exits with the
specified value, then the node will be aborted and will not be
retried.

In the event of retry, all parts of a node within the DAG
are redone, following the same rules regarding node failure
as given above.
The PRE script is executed first,
followed by submitting the program to Condor upon success of
the PRE script.
Failure of the node is then determined by the return value of
the program, the existence and return value of a POST script.

\subsubsection{VARS}

\index{DAGMan!VARS (macro for submit file)}
\index{VARS}
The fifth type of item in the DAG input file provides a
method of defining a macro to be placed into the submit description
file.
These macros are defined on a per-node basis, using the
following format.

\Arg{VARS} \Arg{JobName} \Arg{macroname="string"\Dots}

The definition of the macro is available to use within the
submit description file.  The \verb@macroname@ can be variable
length and consist of alphanumerics (e.g. a..Z and 0..9) and
underscores.  The space character delimits the list of macros when
there is more than one macro defined for each \Arg{JobName}.

Correct syntax requires that the \verb@string@ must be
enclosed in double quotes.
To use a double quote inside \verb@string@,
escape it with the backslash character (\verb@\@).
To add the backslash character itself, use two backslashes (\verb@\\@).

% for version 6.5.3, the VARS are not propagated into rescue dags.

\subsubsection{ABORT-DAG-ON}

\index{DAGMan!ABORT-DAG-ON}
The sixth type of item in the DAG input file provides a way
to abort the entire DAG if a given node returns a specific exit
code.  The syntax for ABORT-DAG-ON:

\Arg{ABORT-DAG-ON} \Arg{JobName} \Arg{AbortExitValue}

If the specified node returns the specified abort exit value, the
DAG is immediately aborted.  The main difference between a node
failure and a DAG abort is that
in the case of an abort, the DAG is stopped immediately, including
removing nodes that are currently running.  In the case of a node
failure, the DAG will continue to run until no more progress can
be made because of the DAG dependencies.

An abort of a DAG is based on exit values from
within a node, 
where the node can contain
a PRE script, the job itself, and a POST script.
If a node has a PRE script and the PRE
script returns the abort exit value, the DAG is aborted.
If the node has no POST script, or \Arg{-NoPostFail} was passed to
\Condor{submit\_dag},
and the job returns the abort exit value,
the DAG is aborted.
If the node has a POST script and \Arg{-NoPostFail} was \emph{not} passed
to \Condor{submit\_dag},
the POST script is run,
and the DAG is aborted if the POST script returns
the abort exit value.

An abort overrides node retries. 
If a node returns the abort exit value,
the DAG is aborted,
even if the node has retries specified.

The value zero is not allowed as an abort exit value.

When a DAG aborts, it exits with the value that caused the abort.
This can be used for DAGs within DAGs,
allowing an inner DAG to cause an abort of an outer DAG.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Submit Description File}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{DAGMan!submit description file with}
Each node in a DAG may be a unique executable, and each may have a unique
submit description file.
Each Condor program may be submitted to a different universe,
for example standard,
vanilla, or DAGMan.

One key limitation:
each Condor submit description file must submit only one job.
There may not be multiple \verb@queue@ commands, or DAGMan will fail.
This requirement exists to enforce the requirements of a well-defined DAG.
If each node of the DAG could cause the submission of multiple
Condor jobs, then it would violate the definition of a DAG.

DAGMan no longer requires that all jobs specify the same log file.
However, if the DAG contains a very large number of jobs, each
specifying its own log file, performance may suffer.  Therefore,
if the DAG contains a large number of jobs, it is best to have
all of the jobs use the same log file.
Another current limitation is that all
Stork jobs currently require a separate log file.
DAGMan enforces the dependencies within a DAG
using the events recorded in the
log file(s) produced by job submission to Condor.

Here is a simple input file for a 
modified version of diamond-shaped DAG example.

\begin{verbatim}
	# Filename: diamond.dag
	#
	JOB  A  diamond_job.condor 
	JOB  B  diamond_job.condor 
	JOB  C  diamond_job.condor	
	JOB  D  diamond_job.condor
	PARENT A CHILD B C
	PARENT B C CHILD D
\end{verbatim}

A single Condor submit description file goes with all the nodes
in this DAG:

\index{DAGMan!example submit description file}
\begin{verbatim}
	# Filename: diamond_job.condor
	#
	executable   = /path/diamond.exe
	output       = diamond.out.$(cluster)
	error        = diamond.err.$(cluster)
	log          = diamond_condor.log
	universe     = vanilla
	notification = NEVER
	queue
\end{verbatim}

This example uses the same Condor submit description file
for all the jobs in the DAG.
This implies that each node within the DAG runs the
same program.
The \MacroU{cluster} macro
is used to produce unique file names for each program's output.
Each \Arg{JOB} is submitted separately, into its own cluster,
so this provides unique names for the output files.

The notification is set to \verb@NEVER@ in this example.
This tells Condor not to send e-mail about the completion of a program
submitted to Condor.
For DAGs with many nodes, this is recommended
to reduce or eliminate excessive numbers of e-mails.

A separate example shows an intended use of a \Arg{VARS} entry
in the DAG.
It can be used to dramatically reduce the number of submit description
files needed for a DAG.
In the case where the submit description file for each node
varies only in file naming, the use of a substitution macro
within the submit description file allows the use of 
a single submit description file.
Note that the user log file for a job currently cannot be specified
using a macro passed from the DAG.

The example uses a single submit description file in the DAG input
file, and uses the \Arg{Vars} entry to name output files.

\begin{verbatim}
	# submit description file called:  theonefile.sub
	executable   = progX
	output       = $(outfilename)
	error        = error.$(outfilename)
	universe     = standard
	queue
\end{verbatim}

The relevant portion of the DAG input file appears as 
\begin{verbatim}
JOB A theonefile.sub
JOB B theonefile.sub
JOB C theonefile.sub

VARS A outfilename="A"
VARS B outfilename="B"
VARS C outfilename="C"
\end{verbatim}

For a DAG like this one with thousands of nodes,
being able to write and maintain a single submit description file 
and a single, yet more complex, DAG input file is preferable.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\label{dagman:submitdag}Job Submission}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A DAG is submitted using the program \Condor{submit\_dag}.
See the manual
page~\pageref{man-condor-submit}
for complete details.
A simple submission has the syntax

\Condor{submit\_dag} \Arg{DAGInputFileName}

\index{DAGMan!job submission}
The example may be submitted with

\begin{verbatim}
condor_submit_dag diamond.dag
\end{verbatim}
In order to guarantee recoverability, the DAGMan program itself
is run as a Condor job.
As such, it needs a submit description file.
\Condor{submit\_dag} produces the needed file,
naming it by appending the \Arg{DAGInputFileName} with
\File{.condor.sub}.
This submit description file may be edited if the DAG is
submitted with

\begin{verbatim}
condor_submit_dag -no_submit diamond.dag
\end{verbatim}
causing \Condor{submit\_dag} to generate the submit description file,
but not submit DAGMan to Condor.
To submit the DAG, once the submit description file is edited,
use

\begin{verbatim}
condor_submit diamond.dag.condor.sub
\end{verbatim}

An optional argument to \Condor{submit\_dag}, \Arg{-maxjobs}, 
is used to specify the maximum number of Condor jobs that DAGMan may
submit to Condor at one time.
It is commonly used when 
there is a limited amount of input file staging capacity.
As a specific example, consider a case where each job will
require 4 Mbytes of input files,
and the jobs will run in a directory with a volume of 100 Mbytes
of free space.
Using the argument \Arg{-maxjobs 25} guarantees that a maximum
of 25 jobs, using a maximum of 100 Mbytes of space,
will be submitted to Condor at one time.

% -maxscripts has been replaced with -maxpre and -maxpost
% Similarly, the \Arg{maxscripts} argument is used to specify the
% maximum number of PRE and POST scripts running at one time.
While the \Arg{-maxjobs} argument is used to limit the number
of Condor jobs submitted at one time,
it may be desirable to limit the number of scripts running
at one time.
The optional \Arg{-maxpre} argument limits the number of PRE
scripts that may be running at one time,
while the optional \Arg{-maxpost} argument limits the number of POST
scripts that may be running at one time.

DAGs that submit jobs to Stork using the \Arg{DATA} keyword must also
specify the Stork user log file, using the \Arg{-storklog} argument.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Job Monitoring}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

After submission, the progress of the DAG can be monitored
by looking at the log file(s),
observing the e-mail that program submission to Condor causes,
or by using \Condor{q} \Arg{-dag}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Job Failure and Job Removal}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Condor{submit\_dag} attempts to check the DAG input file.
If a problem is detected,
\Condor{submit\_dag} prints out an error message and aborts.

DAGMan normally generates a list of job log files to
monitor by examining all of the job submission files.  If
that will not work (some job submission files will be generated
by \Arg{PRE} scripts, for example), you can specify a single
common log file with the \Arg{-log} option.
An example of this submission:
\begin{verbatim}
condor_submit_dag -log diamond_condor.log
\end{verbatim}
This option tells \Condor{submit\_dag} use the given file as
the log file, if no log files are specified in submit files.

To remove an entire DAG, consisting of DAGMan plus
any jobs submitted to Condor or Stork,
remove the DAGMan job running under Condor.
\Condor{q} will list the job number.
Use the job number to remove the job, for example

\footnotesize
\begin{verbatim}

% condor_q
-- Submitter: turunmaa.cs.wisc.edu : <128.105.175.125:36165> : turunmaa.cs.wisc.edu
 ID      OWNER            SUBMITTED     RUN_TIME ST PRI SIZE CMD
    9.0   smoler         10/12 11:47   0+00:01:32 R  0   8.7  condor_dagman -f -
    11.0   smoler         10/12 11:48   0+00:00:00 I  0   3.6  B.out
    12.0   smoler         10/12 11:48   0+00:00:00 I  0   3.6  C.out

         3 jobs; 2 idle, 1 running, 0 held

% condor_rm 9.0
\end{verbatim}
\normalsize

Before the DAGMan job stops running, it uses \Condor{rm}, and/or
\Stork{rm} 
to remove any jobs within the DAG that are running.

In the case where a
machine is scheduled to go down,
DAGMan will clean up memory and exit.
However, it will leave any submitted jobs
in Condor's queue.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Job Recovery:  The Rescue DAG}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{DAGMan!rescue DAG}
DAGMan can help with the resubmission of uncompleted
portions of a DAG when one or more nodes resulted in failure.
If any node in the DAG fails,
the remainder of the DAG is continued until no more forward
progress can be made based on the DAG's dependencies.
At this point, DAGMan produces a file
called a Rescue DAG.

The Rescue DAG is a DAG input file,
functionally the same as the original DAG file.
It additionally contains indication of
successfully completed nodes using the \Arg{DONE}
option in the input description file.
If the DAG is resubmitted using this Rescue DAG input file,
the nodes marked as completed will not be re-executed.

The Rescue DAG is automatically generated by DAGMan when a node
within the DAG fails.
The file is named using the \Arg{DAGInputFileName}, and appending
the suffix \File{.rescue} to it.
Statistics about the failed DAG execution are presented as
comments at the beginning of the Rescue DAG input file.

If the Rescue DAG file is generated before all retries
of a node are completed, 
then the Rescue DAG file will also contain Retry entries.
The number of retries will be set to the appropriate remaining
number of retries. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Visualizing DAGs with \Prog{dot}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\index{DAGMan!dot}
\index{dot}
\index{DAGMan!visualizing DAGs}

It can be helpful to see a picture of a DAG.
DAGMan can assist you in visualizing a DAG by creating
the input files used by the AT\&T Research Labs 
\Prog{graphviz} package. 
\Prog{dot} is a program within this package,
available from \URL{http://www.research.att.com/sw/tools/graphviz},
and it is used to draw pictures of DAGs. 

DAGMan produces one or more dot files as the result of
an extra line
in a DAGMan input file. 
The line appears as
%For example, to produce a single dot
%file that shows the state of your DAG before any jobs are running, add
%the following line:
\begin{verbatim}
	DOT dag.dot
\end{verbatim}

This creates a file called \File{dag.dot}.
which contains
a specification of the DAG before any programs within the DAG
are submitted to Condor.
The \File{dag.dot} file is used to create a visualization
of the DAG by using this file as input to \Prog{dot}.
This example creates a Postscript file, with a visualization of the DAG:

\begin{verbatim}
    dot -Tps dag.dot -o dag.ps
\end{verbatim}

Within the DAGMan input file,
the DOT command can take several optional parameters:

\begin{itemize}

\item \Opt{UPDATE}  This will update the dot file every time a
significant update happens. 

\item \Opt{DONT-UPDATE} Creates a single dot file, when
the DAGMan begins executing. This is the default if the parameter
\Opt{UPDATE} is not used.

\item \Opt{OVERWRITE} Overwrites the dot file each time it
is created. This is the default, unless \Opt{DONT-OVERWRITE}
is specified.

\item \Opt{DONT-OVERWRITE} Used to create multiple dot files, instead
of overwriting the single one specified.
To create file names,
DAGMan uses the name of the file concatenated a period and an
integer. For example, the DAGMan input file line
\begin{verbatim}
	DOT dag.dot DONT-OVERWRITE
\end{verbatim}
causes files
\File{dag.dot.0},
\File{dag.dot.1},
\File{dag.dot.2},
etc. to be created.
This option is
most useful combined with the \Opt{UPDATE} option to
visualize the history of the DAG after it has finished executing. 

\item \OptArg{INCLUDE}{path-to-filename} Includes the contents
of a file given by \File{path-to-filename} in the file produced by the
\Opt{DOT} command.
The include file contents are always placed after the line of
the form
\verb@label=@.
This may be useful if further editing of the created files would
be necessary,
perhaps because you are automatically visualizing the DAG as it
progresses. 

\end{itemize}

If conflicting parameters are used in a DOT command, the last one
listed is used.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\label{sec:DAGsinDAGs}Advanced Usage: A DAG within a DAG}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\index{DAGMan!DAGs within DAGs}

The organization and dependencies of the jobs within a DAG
are the keys to its utility.
There are cases when a DAG is easier to visualize and 
construct hierarchically,
as when a node within a DAG is also a DAG.
Condor DAGMan handles this situation with grace.

Since more than one DAG is being discussed, 
terminology is introduced to clarify which DAG is which. 
Reuse the example DAG as given in 
Figure~\ref{fig:dagman-diamond}.
Assume that node B of this diamond-shaped DAG
will itself be a DAG.
The DAG of node B is called the inner DAG,
and the diamond-shaped DAG is called the outer DAG.

To make DAGs within DAGs,
the essential element is getting the name of the submit description
file for the inner DAG correct within the outer DAG's input
file.

Work on the inner DAG first.
The goal is to generate a Condor submit description file for this inner DAG.
Here is a very simple DAG input file used as an example of the inner DAG.
\begin{verbatim}
	# Filename: inner.dag
	#
	JOB  X  X.submit
	JOB  Y  Y.submit
	JOB  Z  Z.submit
	PARENT X CHILD Y
	PARENT Y CHILD Z
\end{verbatim}

Use \Condor{submit\_dag} to create a submit description file for this
inner dag:
\begin{verbatim}
   condor_submit_dag -no_submit inner.dag
\end{verbatim}
The resulting file will be named \File{inner.dag.condor.sub}.
This file will be needed in the DAG input file of the outer DAG.
The naming of the file is the name of the DAG input file
(\File{inner.dag}) with the suffix \File{.condor.sub}.

A simple example of a DAG input file for the outer DAG is
\begin{verbatim}
	# Filename: diamond.dag
	#
	JOB  A  A.submit 
	JOB  B  inner.dag.condor.sub
	JOB  C  C.submit	
	JOB  D  D.submit
	PARENT A CHILD B C
	PARENT B C CHILD D
\end{verbatim}

The outer DAG is then submitted as before, with
\begin{verbatim}
   condor_submit_dag diamond.dag
\end{verbatim}

More than one level of nested DAGs is supported.

One item to get right:
to locate the log files used in ordering the DAG,
DAGMan either needs a completely flat directory structure
(\emph{all} files for outer and inner DAGs within the same directory)
or
it needs full pathnames to all log files.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\label{sec:MultipleDAGs}Single Submission of Multiple, Independent DAGs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\index{DAGMan!Single submission of multiple, independent DAGs}

A single use of \Condor{submit\_dag} may execute multiple, independent DAGs.
Each independent DAG has its own DAG input file.
These DAG input files are command-line arguments to
\Condor{submit\_dag}
(see the \Condor{submit\_dag} manual page at ~\ref{man-condor-submit-dag}).

Internally, all of the independent DAGs are combined
into a single, larger DAG, with no dependencies between
the original independent DAGs.
As a result,
any generated rescue DAG file represents a single DAG.
The file name of this rescue DAG is based on the DAG input file
listed first within the command-line arguments to
\Condor{submit\_dag}.
Other files such
as \File{dagman.out} and the lock file also have names based on this
first DAG input file.
By default, DAGMan internally renames the nodes to avoid node name collisions.  
If all node names are unique, 
the renaming of nodes may be disabled by
setting the configuration variable \Macro{DAGMAN\_MUNGE\_NODE\_NAMES}
to \Expr{False} (see ~\ref{param:DAGManMungeNodeNames}).

% Karen has editted to this point.
DAGMan currently assumes that all necessary files
(DAG input files and job submit description files)
are located in the same (flat) directory.
Further, this directory is also the current working
directory as \Condor{submit\_dag} is executed.
Locating the multiple, independent DAGs in separate directories 
is not yet supported.
Yet, separate directories will work correctly,
if \emph{all} file names are absolute paths.

Relative paths as file names work only for a specific case.
This case assumes that all file names are given relative to
the current working directory as \Condor{submit\_dag} is executed.
For example,
assume that a directory called \File{parent}
contains two subdirectories called \File{dag1} and
\File{dag2}.
The goal is to submit the two, independent DAGs located within
\File{dag1} and \File{dag2} while the current working directory
is \File{parent} with
\footnotesize
\begin{verbatim}
condor_submit_dag dag1/one.dag dag2/two.dag
\end{verbatim}
\normalsize
To make relative paths work in this example,
the DAG input file \File{one.dag} will need to give the
location of a Condor submit description file for a 
node (within dag1) as
\begin{verbatim}
Job A  dag1/A.submit
\end{verbatim}
and the submit description file (file \File{A.submit})
also needs relative path names such as
\begin{verbatim}
# File name: A.submit, in directory dag1
executable = dag1/A.out
output     = dag1/A.output
error      = dag1/A.error
log        = dag1/dag1.log
universe   = vanilla
queue
\end{verbatim}
Note that these paths are relative to the current working directory
as \Condor{submit\_dag} is executed.
Further note that these relative path names no longer allow the
independent DAG to be submitted on its own when
the  current working directory is the directory containing
the DAG's files (\File{dag1} for this example).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\label{sec:DAGConfig}Configuration}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Configuration variables relating to DAGMan may be found
in 
section~\ref{sec:DAGMan-Config-File-Entries}.

\index{DAGMan|)}
